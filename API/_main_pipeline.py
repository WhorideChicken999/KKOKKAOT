import cv2
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
from pathlib import Path
from ultralytics import YOLO
from transformers import CLIPProcessor, CLIPModel
from torchvision import models, transforms
import chromadb
import psycopg2
from psycopg2.extras import Json
import json
import pandas as pd
from typing import Dict, Tuple, Optional, List

# Background Remover ê´€ë ¨ import
try:
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    print("âš ï¸ rembgê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Background Remover ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    REMBG_AVAILABLE = False

# GPU ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}")


class FashionPipeline:
    """ê°€ìƒì˜·ì¥ ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì—…ë°ì´íŠ¸ëœ ë²„ì „)"""
    
    def __init__(self, 
                style_model_path: str = "D:/kkokkaot/API/pre_trained_weights/k_fashion_best_model.pth",
                yolo_detection_path: str = "D:/kkokkaot/API/pre_trained_weights/yolo_best.pt",
                # ìƒˆë¡œìš´ ì˜ë¥˜ë³„ ëª¨ë¸ ê²½ë¡œ
                top_model_path: str = "D:/kkokkaot/models/top/best_model.pth",
                bottom_model_path: str = "D:/kkokkaot/models/bottom/best_model.pth",
                outer_model_path: str = "D:/kkokkaot/models/outer/best_model.pth",
                dress_model_path: str = "D:/kkokkaot/models/dress/best_model.pth",
                schema_path: str = "D:/kkokkaot/API/kfashion_attributes_schema.csv",
                yolo_pose_path: str = None,  # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
                chroma_path: str = "./chroma_db",
                db_config: dict = None):
        """ì´ˆê¸°í™”"""
        
        print("\n=== ìƒˆë¡œìš´ íŒ¨ì…˜ íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ë¡œë”© ì¤‘ ===")
        
        # 1. ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ
        print("1. ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ...")
        self.style_model, self.style_classes = self.load_style_model(style_model_path)
        
        # 2. YOLO Detection ëª¨ë¸ ë¡œë“œ
        print("2. YOLO Detection ëª¨ë¸ ë¡œë“œ...")
        self.yolo_detection_model = YOLO(yolo_detection_path)
        
        # 3. ì˜ë¥˜ë³„ ì†ì„± ëª¨ë¸ ë¡œë“œ
        print("3. ì˜ë¥˜ë³„ ì†ì„± ëª¨ë¸ ë¡œë“œ...")
        self.category_models = self.load_category_models(
            top_model_path, bottom_model_path, outer_model_path, dress_model_path
        )
        
        # 4. ìŠ¤í‚¤ë§ˆ ë¡œë“œ
        print("4. ì†ì„± ìŠ¤í‚¤ë§ˆ ë¡œë“œ...")
        self.schema = self.load_schema(schema_path)
        
        # 5. YOLO Pose ëª¨ë¸ (ì„ íƒì , ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´)
        if yolo_pose_path:
            print("5. YOLO Pose ë¡œë“œ...")
            self.yolo_model = YOLO(yolo_pose_path)
        else:
            print("5. YOLO Pose ê±´ë„ˆë›°ê¸°...")
            self.yolo_model = None
        
        # 6. Background Remover (ëˆ„ë¼ë”°ê¸°)
        if REMBG_AVAILABLE:
            print("6. Background Remover ì´ˆê¸°í™”...")
            try:
                # Background Remover ì„¸ì…˜ ì´ˆê¸°í™” (u2net ëª¨ë¸ ì‚¬ìš©)
                self.rembg_session = new_session('u2net')
                self.rembg_available = True
                print("âœ… Background Remover ì´ˆê¸°í™” ì™„ë£Œ!")
            except Exception as e:
                print(f"âš ï¸ Background Remover ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.rembg_session = None
                self.rembg_available = False
        else:
            print("6. Background Remover ê±´ë„ˆë›°ê¸°...")
            self.rembg_session = None
            self.rembg_available = False
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # 7. CLIP ëª¨ë¸ (ì„ë² ë”©ìš©)
        print("7. CLIP ëª¨ë¸ ë¡œë“œ...")
        self.clip_model, self.clip_processor = self.load_clip_model()
        
        # 8. ChromaDB
        print("8. ChromaDB ì—°ê²°...")
        self.chroma_client = chromadb.PersistentClient(path=chroma_path)
        try:
            self.chroma_collection = self.chroma_client.get_collection(name="fashion_collection")
        except:
            self.chroma_collection = self.chroma_client.create_collection(name="fashion_collection")
        
        # 9. PostgreSQL
        print("9. PostgreSQL ì—°ê²°...")
        if db_config is None:
            db_config = {
                'host': 'localhost',
                'port': 5432,
                'database': 'kkokkaot_closet',
                'user': 'postgres',
                'password': '000000'
            }
        self.db_config = db_config
        self.db_conn = psycopg2.connect(**db_config)
        
        print("\nâœ“ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    def load_style_model(self, model_path: str):
        """ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ"""
        try:
            checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)
            
            # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸
            if 'model_state_dict' in checkpoint:
                # ìƒˆë¡œìš´ ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° (í•™ìŠµëœ ëª¨ë¸)
                model_state_dict = checkpoint['model_state_dict']
                class_to_idx = checkpoint.get('class_to_idx', {})
                
                # í´ë˜ìŠ¤ ê°œìˆ˜ í™•ì¸
                num_classes = len(class_to_idx) if class_to_idx else 22
                
                # KFashionModel ì»¤ìŠ¤í…€ ëª¨ë¸ êµ¬ì¡° ì‚¬ìš©
                model = self._create_kfashion_model(num_classes)
                model.load_state_dict(model_state_dict)
                model.to(DEVICE)
                model.eval()
                
                # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ
                if class_to_idx:
                    style_classes = [k for k, v in sorted(class_to_idx.items(), key=lambda x: x[1])]
                else:
                    # ê¸°ë³¸ ìŠ¤íƒ€ì¼ í´ë˜ìŠ¤
                    style_classes = [
                        'ë¡œë§¨í‹±', 'í˜ë¯¸ë‹Œ', 'ì„¹ì‹œ', 'ì  ë”ë¦¬ìŠ¤/ì  ë”í”Œë£¨ì´ë“œ', 'ë§¤ìŠ¤í˜ë¦°', 'í†°ë³´ì´',
                        'íˆí”¼', 'ì˜¤ë¦¬ì—”íƒˆ', 'ì›¨ìŠ¤í„´', 'ì»¨íŠ¸ë¦¬', 'ë¦¬ì¡°íŠ¸', 'ëª¨ë˜',
                        'ì†Œí”¼ìŠ¤íŠ¸ì¼€ì´í‹°ë“œ', 'ì•„ë°©ê°€ë¥´ë“œ', 'í‘í¬', 'í‚¤ì¹˜/í‚¤ëœíŠ¸', 'ë ˆíŠ¸ë¡œ',
                        'í™í•©', 'í´ë˜ì‹', 'í”„ë ˆí”¼', 'ìŠ¤íŠ¸ë¦¬íŠ¸', 'ë°€ë¦¬í„°ë¦¬', 'ìŠ¤í¬í‹°'
                    ]
                
            else:
                # ê¸°ì¡´ êµ¬ì¡° (ì§ì ‘ state_dict)
                num_classes = 22
                model = models.resnet50(pretrained=False)
                model.fc = nn.Linear(model.fc.in_features, num_classes)
                model.load_state_dict(checkpoint)
                model.to(DEVICE)
                model.eval()
                
                style_classes = [
                    'ë¡œë§¨í‹±', 'í˜ë¯¸ë‹Œ', 'ì„¹ì‹œ', 'ì  ë”ë¦¬ìŠ¤/ì  ë”í”Œë£¨ì´ë“œ', 'ë§¤ìŠ¤í˜ë¦°', 'í†°ë³´ì´',
                    'íˆí”¼', 'ì˜¤ë¦¬ì—”íƒˆ', 'ì›¨ìŠ¤í„´', 'ì»¨íŠ¸ë¦¬', 'ë¦¬ì¡°íŠ¸', 'ëª¨ë˜',
                    'ì†Œí”¼ìŠ¤íŠ¸ì¼€ì´í‹°ë“œ', 'ì•„ë°©ê°€ë¥´ë“œ', 'í‘í¬', 'í‚¤ì¹˜/í‚¤ëœíŠ¸', 'ë ˆíŠ¸ë¡œ',
                    'í™í•©', 'í´ë˜ì‹', 'í”„ë ˆí”¼', 'ìŠ¤íŠ¸ë¦¬íŠ¸', 'ë°€ë¦¬í„°ë¦¬', 'ìŠ¤í¬í‹°'
                ]
            
            print(f"  âœ“ ìŠ¤íƒ€ì¼ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({len(style_classes)}ê°œ í´ë˜ìŠ¤)")
            return model, style_classes
            
        except Exception as e:
            print(f"âŒ ìŠ¤íƒ€ì¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None, None
    
    def load_category_models(self, top_model_path: str, bottom_model_path: str, 
                           outer_model_path: str, dress_model_path: str):
        """ì˜ë¥˜ë³„ ì†ì„± ëª¨ë¸ ë¡œë“œ (ìƒˆë¡œìš´ êµ¬ì¡°)"""
        category_models = {}
        
        # ê° ì˜ë¥˜ë³„ ëª¨ë¸ ë¡œë“œ
        model_paths = {
            'ìƒì˜': top_model_path,
            'í•˜ì˜': bottom_model_path, 
            'ì•„ìš°í„°': outer_model_path,
            'ì›í”¼ìŠ¤': dress_model_path
        }
        
        for category, model_path in model_paths.items():
            try:
                if not Path(model_path).exists():
                    print(f"  âš ï¸ {category} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                    continue
                
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)
                
                # ëª¨ë¸ êµ¬ì¡° ë° ì¸ì½”ë” ì •ë³´ ì¶”ì¶œ
                encoders = checkpoint.get('encoders', {})
                schema = checkpoint.get('schema', {})
                
                # ê° ì˜ë¥˜ë³„ ì†ì„± ì •ì˜
                if category == 'ìƒì˜':
                    attributes = ['category', 'color', 'material', 'print', 'fit', 'style', 'sleeve']
                elif category == 'í•˜ì˜':
                    attributes = ['category', 'color', 'material', 'print', 'fit', 'style', 'length']
                elif category == 'ì•„ìš°í„°':
                    attributes = ['category', 'color', 'material', 'print', 'fit', 'style', 'sleeve']
                elif category == 'ì›í”¼ìŠ¤':
                    attributes = ['category', 'color', 'material', 'print', 'style']
                
                category_models[category] = {
                    'model': None,  # ì‹¤ì œ ëª¨ë¸ì€ predict_category_attributesì—ì„œ ë¡œë“œ
                    'checkpoint': checkpoint,
                    'encoders': encoders,
                    'schema': schema,
                    'attributes': attributes
                }
                
                print(f"  âœ“ {category} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({len(attributes)}ê°œ ì†ì„±)")
                
            except Exception as e:
                print(f"  âŒ {category} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        return category_models
    
    def load_schema(self, schema_path: str):
        """ì†ì„± ìŠ¤í‚¤ë§ˆ ë¡œë“œ"""
        try:
            schema_df = pd.read_csv(schema_path)
            return schema_df
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def load_clip_model(self):
        """CLIP ëª¨ë¸ ë¡œë“œ"""
        try:
            clip_model = CLIPModel.from_pretrained("patrickjohncyh/fashion-clip").to(DEVICE)
            clip_processor = CLIPProcessor.from_pretrained("patrickjohncyh/fashion-clip")
        except:
            clip_model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14").to(DEVICE)
            clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
        
        clip_model.eval()
        return clip_model, clip_processor
    
    def predict_style(self, image: np.ndarray) -> Dict:
        """ì „ì²´ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ì˜ˆì¸¡"""
        print("[1/7] ì „ì²´ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ì¤‘...")
        
        if self.style_model is None:
            return {'style': 'Unknown', 'confidence': 0.0}
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        pil_image = Image.fromarray(image)
        image_tensor = self.transform(pil_image).unsqueeze(0).to(DEVICE)
        
        with torch.no_grad():
            outputs = self.style_model(image_tensor)
            probs = torch.softmax(outputs, dim=1)[0]
            style_idx = probs.argmax().item()
            confidence = probs[style_idx].item()
            style = self.style_classes[style_idx]
        
        result = {
            'style': style,
            'confidence': confidence
        }
        
        print(f"  - ìŠ¤íƒ€ì¼: {style} ({confidence:.2f})")
        return result
    
    def predict_category_attributes(self, category: str, cropped_image: np.ndarray) -> Dict:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ì†ì„± ì˜ˆì¸¡ (ìƒˆë¡œìš´ êµ¬ì¡°)"""
        print(f"  [3/7] {category} ì†ì„± ì˜ˆì¸¡ ì¤‘...")
        
        if category not in self.category_models:
            return {}
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        pil_image = Image.fromarray(cropped_image)
        image_tensor = self.transform(pil_image).unsqueeze(0).to(DEVICE)
        
        attributes = {}
        
        try:
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            model_info = self.category_models[category]
            checkpoint = model_info['checkpoint']
            encoders = model_info['encoders']
            attributes_list = model_info['attributes']
            
            # ëª¨ë¸ êµ¬ì¡° ì¬êµ¬ì„± (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ êµ¬ì¡°)
            if category == 'ìƒì˜':
                model = self._create_top_model(encoders)
            elif category == 'í•˜ì˜':
                model = self._create_bottom_model(encoders)
            elif category == 'ì•„ìš°í„°':
                model = self._create_outer_model(encoders)
            elif category == 'ì›í”¼ìŠ¤':
                model = self._create_dress_model(encoders)
            
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
            model.load_state_dict(checkpoint['model_state_dict'])
            model.to(DEVICE)
            model.eval()
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            with torch.no_grad():
                outputs = model(image_tensor)
                
                # ê° ì†ì„±ë³„ ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
                for attr in attributes_list:
                    if attr in outputs:
                        attr_output = outputs[attr]
                        probs = torch.softmax(attr_output, dim=1)[0]
                        pred_idx = probs.argmax().item()
                        confidence = probs[pred_idx].item()
                        
                        # ì¸ì½”ë”ë¡œ ë””ì½”ë”©
                        predicted_class = encoders[attr].inverse_transform([pred_idx])[0]
                        
                        attributes[attr] = {
                            'value': predicted_class,
                            'confidence': confidence
                        }
                        
                        print(f"    - {attr}: {predicted_class} ({confidence:.2f})")
            
        except Exception as e:
            print(f"    âŒ {category} ì†ì„± ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        return attributes
    
    def _create_top_model(self, encoders):
        """ìƒì˜ ëª¨ë¸ ìƒì„±"""
        from torchvision import models
        import torch.nn as nn
        
        class TopFashionModel(nn.Module):
            def __init__(self, num_category, num_color, num_material, num_print, num_fit, num_style, num_sleeve):
                super(TopFashionModel, self).__init__()
                
                # EfficientNet-B0ë¥¼ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©
                self.backbone = models.efficientnet_b0(pretrained=True)
                
                # íŠ¹ì§• ì¶”ì¶œê¸° (ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ ì œê±°)
                self.features = nn.Sequential(*list(self.backbone.children())[:-1])
                
                # íŠ¹ì§• ì°¨ì›
                feature_dim = 1280
                
                # ê³µìœ  íŠ¹ì§• ë³€í™˜ì¸µ
                self.shared_fc = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(feature_dim, 512),
                    nn.ReLU(),
                    nn.Dropout(0.3)
                )
                
                # ê° íƒœìŠ¤í¬ë³„ í—¤ë“œ
                self.category_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_category)
                )
                
                self.color_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_color)
                )
                
                self.material_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_material)
                )
                
                self.print_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_print)
                )
                
                self.fit_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_fit)
                )
                
                self.style_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_style)
                )
                
                self.sleeve_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_sleeve)
                )
            
            def forward(self, x):
                # ê³µìœ  íŠ¹ì§• ì¶”ì¶œ
                features = self.features(x)
                shared_features = self.shared_fc(features)
                
                # ê° íƒœìŠ¤í¬ë³„ ì˜ˆì¸¡
                category_out = self.category_head(shared_features)
                color_out = self.color_head(shared_features)
                material_out = self.material_head(shared_features)
                print_out = self.print_head(shared_features)
                fit_out = self.fit_head(shared_features)
                style_out = self.style_head(shared_features)
                sleeve_out = self.sleeve_head(shared_features)
                
                return {
                    'category': category_out,
                    'color': color_out,
                    'material': material_out,
                    'print': print_out,
                    'fit': fit_out,
                    'style': style_out,
                    'sleeve': sleeve_out
                }
        
        return TopFashionModel(
            num_category=len(encoders['category'].classes_),
            num_color=len(encoders['color'].classes_),
            num_material=len(encoders['material'].classes_),
            num_print=len(encoders['print'].classes_),
            num_fit=len(encoders['fit'].classes_),
            num_style=len(encoders['style'].classes_),
            num_sleeve=len(encoders['sleeve'].classes_)
        )
    
    def _create_bottom_model(self, encoders):
        """í•˜ì˜ ëª¨ë¸ ìƒì„±"""
        from torchvision import models
        import torch.nn as nn
        
        class BottomFashionModel(nn.Module):
            def __init__(self, num_category, num_color, num_material, num_print, num_fit, num_style, num_length):
                super(BottomFashionModel, self).__init__()
                
                # EfficientNet-B0ë¥¼ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©
                self.backbone = models.efficientnet_b0(pretrained=True)
                
                # íŠ¹ì§• ì¶”ì¶œê¸° (ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ ì œê±°)
                self.features = nn.Sequential(*list(self.backbone.children())[:-1])
                
                # íŠ¹ì§• ì°¨ì›
                feature_dim = 1280
                
                # ê³µìœ  íŠ¹ì§• ë³€í™˜ì¸µ
                self.shared_fc = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(feature_dim, 512),
                    nn.ReLU(),
                    nn.Dropout(0.3)
                )
                
                # ê° íƒœìŠ¤í¬ë³„ í—¤ë“œ
                self.category_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_category)
                )
                
                self.color_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_color)
                )
                
                self.material_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_material)
                )
                
                self.print_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_print)
                )
                
                self.fit_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_fit)
                )
                
                self.style_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_style)
                )
                
                self.length_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_length)
                )
            
            def forward(self, x):
                # ê³µìœ  íŠ¹ì§• ì¶”ì¶œ
                features = self.features(x)
                shared_features = self.shared_fc(features)
                
                # ê° íƒœìŠ¤í¬ë³„ ì˜ˆì¸¡
                category_out = self.category_head(shared_features)
                color_out = self.color_head(shared_features)
                material_out = self.material_head(shared_features)
                print_out = self.print_head(shared_features)
                fit_out = self.fit_head(shared_features)
                style_out = self.style_head(shared_features)
                length_out = self.length_head(shared_features)
                
                return {
                    'category': category_out,
                    'color': color_out,
                    'material': material_out,
                    'print': print_out,
                    'fit': fit_out,
                    'style': style_out,
                    'length': length_out
                }
        
        return BottomFashionModel(
            num_category=len(encoders['category'].classes_),
            num_color=len(encoders['color'].classes_),
            num_material=len(encoders['material'].classes_),
            num_print=len(encoders['print'].classes_),
            num_fit=len(encoders['fit'].classes_),
            num_style=len(encoders['style'].classes_),
            num_length=len(encoders['length'].classes_)
        )
    
    def _create_outer_model(self, encoders):
        """ì•„ìš°í„° ëª¨ë¸ ìƒì„±"""
        from torchvision import models
        import torch.nn as nn
        
        class OuterFashionModel(nn.Module):
            def __init__(self, num_category, num_color, num_material, num_print, num_fit, num_style, num_sleeve):
                super(OuterFashionModel, self).__init__()
                
                # EfficientNet-B0ë¥¼ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©
                self.backbone = models.efficientnet_b0(pretrained=True)
                
                # íŠ¹ì§• ì¶”ì¶œê¸° (ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ ì œê±°)
                self.features = nn.Sequential(*list(self.backbone.children())[:-1])
                
                # íŠ¹ì§• ì°¨ì›
                feature_dim = 1280
                
                # ê³µìœ  íŠ¹ì§• ë³€í™˜ì¸µ
                self.shared_fc = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(feature_dim, 512),
                    nn.ReLU(),
                    nn.Dropout(0.3)
                )
                
                # ê° íƒœìŠ¤í¬ë³„ í—¤ë“œ
                self.category_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_category)
                )
                
                self.color_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_color)
                )
                
                self.material_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_material)
                )
                
                self.print_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_print)
                )
                
                self.fit_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_fit)
                )
                
                self.style_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_style)
                )
                
                self.sleeve_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_sleeve)
                )
            
            def forward(self, x):
                # ê³µìœ  íŠ¹ì§• ì¶”ì¶œ
                features = self.features(x)
                shared_features = self.shared_fc(features)
                
                # ê° íƒœìŠ¤í¬ë³„ ì˜ˆì¸¡
                category_out = self.category_head(shared_features)
                color_out = self.color_head(shared_features)
                material_out = self.material_head(shared_features)
                print_out = self.print_head(shared_features)
                fit_out = self.fit_head(shared_features)
                style_out = self.style_head(shared_features)
                sleeve_out = self.sleeve_head(shared_features)
                
                return {
                    'category': category_out,
                    'color': color_out,
                    'material': material_out,
                    'print': print_out,
                    'fit': fit_out,
                    'style': style_out,
                    'sleeve': sleeve_out
                }
        
        return OuterFashionModel(
            num_category=len(encoders['category'].classes_),
            num_color=len(encoders['color'].classes_),
            num_material=len(encoders['material'].classes_),
            num_print=len(encoders['print'].classes_),
            num_fit=len(encoders['fit'].classes_),
            num_style=len(encoders['style'].classes_),
            num_sleeve=len(encoders['sleeve'].classes_)
        )
    
    def _create_dress_model(self, encoders):
        """ë“œë ˆìŠ¤ ëª¨ë¸ ìƒì„±"""
        from torchvision import models
        import torch.nn as nn
        
        class DressFashionModel(nn.Module):
            def __init__(self, num_category, num_color, num_material, num_print, num_style):
                super(DressFashionModel, self).__init__()
                
                # EfficientNet-B0ë¥¼ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©
                self.backbone = models.efficientnet_b0(pretrained=True)
                
                # íŠ¹ì§• ì¶”ì¶œê¸° (ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µ ì œê±°)
                self.features = nn.Sequential(*list(self.backbone.children())[:-1])
                
                # íŠ¹ì§• ì°¨ì›
                feature_dim = 1280
                
                # ê³µìœ  íŠ¹ì§• ë³€í™˜ì¸µ
                self.shared_fc = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(feature_dim, 512),
                    nn.ReLU(),
                    nn.Dropout(0.3)
                )
                
                # ê° íƒœìŠ¤í¬ë³„ í—¤ë“œ
                self.category_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_category)
                )
                
                self.color_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_color)
                )
                
                self.material_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_material)
                )
                
                self.print_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_print)
                )
                
                self.style_head = nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_style)
                )
            
            def forward(self, x):
                # ê³µìœ  íŠ¹ì§• ì¶”ì¶œ
                features = self.features(x)
                shared_features = self.shared_fc(features)
                
                # ê° íƒœìŠ¤í¬ë³„ ì˜ˆì¸¡
                category_out = self.category_head(shared_features)
                color_out = self.color_head(shared_features)
                material_out = self.material_head(shared_features)
                print_out = self.print_head(shared_features)
                style_out = self.style_head(shared_features)
                
                return {
                    'category': category_out,
                    'color': color_out,
                    'material': material_out,
                    'print': print_out,
                    'style': style_out
                }
        
        return DressFashionModel(
            num_category=len(encoders['category'].classes_),
            num_color=len(encoders['color'].classes_),
            num_material=len(encoders['material'].classes_),
            num_print=len(encoders['print'].classes_),
            num_style=len(encoders['style'].classes_)
        )
    
    def _create_kfashion_model(self, num_classes):
        """KFashionModel ì»¤ìŠ¤í…€ ëª¨ë¸ ìƒì„±"""
        from torchvision import models
        import torch.nn as nn
        
        class KFashionModel(nn.Module):
            def __init__(self, num_classes):
                super(KFashionModel, self).__init__()
                
                # EfficientNet-B0 ë°±ë³¸
                self.backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')
                
                # ë°±ë³¸ì˜ ì¼ë¶€ ë ˆì´ì–´ ê³ ì • (Fine-tuning)
                # EfficientNetì˜ features ë¶€ë¶„ì—ì„œ ì•ìª½ ë ˆì´ì–´ë“¤ ê³ ì •
                for i, param in enumerate(self.backbone.features.parameters()):
                    if i < 100:  # ì•ìª½ íŒŒë¼ë¯¸í„°ë“¤ ê³ ì •
                        param.requires_grad = False
                
                # Classifier êµì²´
                in_features = self.backbone.classifier[1].in_features
                self.backbone.classifier = nn.Sequential(
                    nn.BatchNorm1d(in_features),
                    nn.Dropout(0.5),
                    nn.Linear(in_features, 512),
                    nn.ReLU(),
                    nn.BatchNorm1d(512),
                    nn.Dropout(0.3),
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, num_classes)
                )
            
            def forward(self, x):
                return self.backbone(x)
        
        return KFashionModel(num_classes)
    
    def reconnect_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¬ì‹œë„"""
        try:
            if hasattr(self, 'db_conn') and self.db_conn:
                self.db_conn.close()
        except:
            pass
        
        try:
            self.db_conn = psycopg2.connect(**self.db_config)
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì¬ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì¬ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def detect_and_crop_categories(self, image_path: str) -> Dict:
        """YOLOë¡œ ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° í¬ë¡­"""
        print("[2/7] YOLO ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° í¬ë¡­ ì¤‘...")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        print(f"  ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image_rgb.shape}")
        
        # YOLO Detection ì¶”ë¡ 
        try:
            results = self.yolo_detection_model(image_path, verbose=False)
            print(f"  ğŸ” YOLO ê²°ê³¼: {len(results[0].boxes)}ê°œ ë°•ìŠ¤ ê°ì§€")
            
            # YOLO ê²°ê³¼ ìƒì„¸ ì •ë³´ ì¶œë ¥
            if len(results[0].boxes) > 0:
                print(f"  ğŸ“Š ë°•ìŠ¤ ì •ë³´:")
                for i, box in enumerate(results[0].boxes):
                    class_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    print(f"    ë°•ìŠ¤ {i}: class_id={class_id}, confidence={confidence:.3f}, bbox=({x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f})")
            else:
                print("  âŒ YOLOê°€ ì•„ë¬´ê²ƒë„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
                print("  ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
                print("    - ì´ë¯¸ì§€ì— ì˜ë¥˜ê°€ ëª…í™•í•˜ì§€ ì•ŠìŒ")
                print("    - YOLO ëª¨ë¸ì´ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•˜ì§€ ëª»í•¨")
                print("    - confidence thresholdê°€ ë„ˆë¬´ ë†’ìŒ")
                
        except Exception as e:
            print(f"  âŒ YOLO ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return {
                'original': image_rgb,
                'detected_items': {},
                'has_ìƒì˜': False,
                'has_í•˜ì˜': False,
                'has_ì•„ìš°í„°': False,
                'has_ì›í”¼ìŠ¤': False
            }
        
        detected_items = {
            'ìƒì˜': [],
            'í•˜ì˜': [],
            'ì•„ìš°í„°': [],
            'ì›í”¼ìŠ¤': []
        }
        
        # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘ (YOLO ëª¨ë¸ì˜ ì‹¤ì œ í´ë˜ìŠ¤ ìˆœì„œ)
        class_names = ['outer', 'top', 'bottom', 'dress']  # ì˜ì–´ë¡œ ìˆ˜ì •
        category_mapping = {
            'outer': 'ì•„ìš°í„°',
            'top': 'ìƒì˜',
            'bottom': 'í•˜ì˜',
            'dress': 'ì›í”¼ìŠ¤'
        }
        
        if len(results[0].boxes) > 0:
            boxes = results[0].boxes
            print(f"  ğŸ“¦ ê°ì§€ëœ ë°•ìŠ¤ ê°œìˆ˜: {len(boxes)}")
            
            for i, box in enumerate(boxes):
                class_id = int(box.cls[0])
                confidence = float(box.conf[0])
                
                print(f"    ë°•ìŠ¤ {i}: class_id={class_id}, confidence={confidence:.3f}")
                
                # confidence 0.3ìœ¼ë¡œ ë‚®ì¶¤ (ë” ë§ì€ ê°ì§€ í—ˆìš©)
                if confidence >= 0.3 and class_id < len(class_names):
                    class_name_en = class_names[class_id]
                    class_name_ko = category_mapping.get(class_name_en)
                    
                    print(f"    â†’ í´ë˜ìŠ¤: {class_name_en} â†’ {class_name_ko}")
                    
                    if class_name_ko:
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                        
                        print(f"    â†’ ë°”ìš´ë”© ë°•ìŠ¤: ({x1},{y1},{x2},{y2})")
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
                        if x1 >= 0 and y1 >= 0 and x2 > x1 and y2 > y1 and x2 <= image_rgb.shape[1] and y2 <= image_rgb.shape[0]:
                            # ì´ë¯¸ì§€ í¬ë¡­
                            cropped_image = image_rgb[y1:y2, x1:x2]
                            
                            if cropped_image.size > 0:
                                detected_items[class_name_ko].append({
                                    'bbox': (x1, y1, x2, y2),
                                    'confidence': confidence,
                                    'cropped_image': cropped_image
                                })
                                
                                print(f"  âœ… {class_name_ko}: confidence={confidence:.2f}, í¬ë¡­ í¬ê¸°={cropped_image.shape}")
                            else:
                                print(f"  âŒ {class_name_ko}: í¬ë¡­ëœ ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆìŒ")
                        else:
                            print(f"  âŒ {class_name_ko}: ìœ íš¨í•˜ì§€ ì•Šì€ ë°”ìš´ë”© ë°•ìŠ¤")
                    else:
                        print(f"  âŒ í´ë˜ìŠ¤ ë§¤í•‘ ì‹¤íŒ¨: {class_name_en}")
                else:
                    print(f"  âŒ ë°•ìŠ¤ {i}: confidence={confidence:.3f} < 0.3 ë˜ëŠ” class_id={class_id} >= {len(class_names)}")
        else:
            print("  âŒ ê°ì§€ëœ ë°•ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê°€ì¥ ë†’ì€ confidence ì„ íƒ
        final_items = {}
        for category, items in detected_items.items():
            if items:
                best_item = max(items, key=lambda x: x['confidence'])
                final_items[category] = best_item
                print(f"  âœ… {category} ì„ íƒ: confidence={best_item['confidence']:.2f}")
        
        # YOLO ê°ì§€ ì‹¤íŒ¨ ì‹œ ì„ì‹œ í•´ê²°ì±…: ì „ì²´ ì´ë¯¸ì§€ë¥¼ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¡œ ì‚¬ìš©
        if not final_items:
            print("  âš ï¸ YOLO ê°ì§€ ì‹¤íŒ¨ - ì „ì²´ ì´ë¯¸ì§€ë¥¼ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¡œ ì‚¬ìš©")
            final_items = {
                'ìƒì˜': {
                    'bbox': (0, 0, image_rgb.shape[1], image_rgb.shape[0]),
                    'confidence': 0.5,
                    'cropped_image': image_rgb
                },
                'í•˜ì˜': {
                    'bbox': (0, 0, image_rgb.shape[1], image_rgb.shape[0]),
                    'confidence': 0.5,
                    'cropped_image': image_rgb
                }
            }
            print("  ğŸ”§ ì„ì‹œ í•´ê²°ì±… ì ìš©: ìƒì˜, í•˜ì˜ë¡œ ë¶„ë¥˜")
        
        return {
            'original': image_rgb,
            'detected_items': final_items,
            'has_ìƒì˜': 'ìƒì˜' in final_items,
            'has_í•˜ì˜': 'í•˜ì˜' in final_items,
            'has_ì•„ìš°í„°': 'ì•„ìš°í„°' in final_items,
            'has_ì›í”¼ìŠ¤': 'ì›í”¼ìŠ¤' in final_items
        }

    
    
    def create_embedding(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
        print("[4/7] ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...")
        
        pil_image = Image.fromarray(image)
        
        inputs = self.clip_processor(
            images=pil_image,
            return_tensors="pt",
            padding=True
        ).to(DEVICE)
        
        with torch.no_grad():
            image_features = self.clip_model.get_image_features(**inputs)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        
        embedding = image_features.cpu().numpy()[0]
        print(f"  - ì„ë² ë”© ì°¨ì›: {embedding.shape}")
        
        return embedding
    
    
    def save_to_postgresql(self, user_id: int, image_path: str, 
                          style_result: Dict, detection_result: Dict,
                          category_attributes: Dict, chroma_id: str = None) -> int:
        """PostgreSQLì— ì €ì¥"""
        print("[5/7] PostgreSQLì— ì €ì¥ ì¤‘...")
        
        try:
            self.db_conn.rollback()
        except:
            pass
        
        try:
            with self.db_conn.cursor() as cur:
                # wardrobe_items ì‚½ì…
                cur.execute("""
                    INSERT INTO wardrobe_items (
                        user_id, original_image_path, style, style_confidence,
                        has_top, has_bottom, has_outer, has_dress,
                        chroma_embedding_id
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    RETURNING item_id
                """, (
                    user_id, 
                    image_path,
                    style_result['style'],
                    style_result['confidence'],
                    detection_result['has_ìƒì˜'],
                    detection_result['has_í•˜ì˜'],
                    detection_result['has_ì•„ìš°í„°'],
                    detection_result['has_ì›í”¼ìŠ¤'],
                    chroma_id
                ))
                
                item_id = cur.fetchone()[0]
                
                # ê° ì¹´í…Œê³ ë¦¬ë³„ ì†ì„± ì €ì¥ (ìƒˆë¡œìš´ êµ¬ì¡°)
                for category, attributes in category_attributes.items():
                    if attributes:
                        # ì¹´í…Œê³ ë¦¬ë³„ í…Œì´ë¸”ì— ì €ì¥ (ì˜ì–´ í…Œì´ë¸”ëª… ì‚¬ìš©)
                        category_mapping = {
                            'ìƒì˜': 'top_attributes_new',
                            'í•˜ì˜': 'bottom_attributes_new', 
                            'ì•„ìš°í„°': 'outer_attributes_new',
                            'ì›í”¼ìŠ¤': 'dress_attributes_new'
                        }
                        table_name = category_mapping.get(category, f"{category.lower()}_attributes")
                        
                        print(f"  ğŸ’¾ {category} ì†ì„± ì €ì¥ ì¤‘... (í…Œì´ë¸”: {table_name})")
                        print(f"    - ì†ì„± ê°œìˆ˜: {len(attributes)}")
                        for attr_name, attr_data in attributes.items():
                            print(f"    - {attr_name}: {attr_data.get('value', 'Unknown')} ({attr_data.get('confidence', 0.0):.2f})")
                        
                        # ê¸°ë³¸ ì†ì„± ê°’ ì¶”ì¶œ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ ê³µí†µ)
                        category_val = attributes.get('category', {}).get('value', 'Unknown')
                        color_val = attributes.get('color', {}).get('value', 'Unknown')
                        material_val = attributes.get('material', {}).get('value', 'Unknown')
                        print_val = attributes.get('print', {}).get('value', 'Unknown')
                        style_val = attributes.get('style', {}).get('value', 'Unknown')
                        
                        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ìˆ˜ ì†ì„±
                        fit_val = attributes.get('fit', {}).get('value', 'Unknown')
                        sleeve_val = attributes.get('sleeve', {}).get('value', 'Unknown')
                        length_val = attributes.get('length', {}).get('value', 'Unknown')
                        
                        # ì‹ ë¢°ë„ ì¶”ì¶œ
                        category_conf = attributes.get('category', {}).get('confidence', 0.0)
                        color_conf = attributes.get('color', {}).get('confidence', 0.0)
                        fit_conf = attributes.get('fit', {}).get('confidence', 0.0)
                        
                        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‹¤ë¥¸ í•„ë“œ ì €ì¥
                        if category == 'ìƒì˜':
                            cur.execute(f"""
                                INSERT INTO {table_name} (
                                    item_id, category, color, fit, material, print_pattern, style, sleeve_length,
                                    category_confidence, color_confidence, fit_confidence
                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                            """, (
                                item_id, category_val, color_val, fit_val, material_val, print_val, style_val, sleeve_val,
                                category_conf, color_conf, fit_conf
                            ))
                        elif category == 'í•˜ì˜':
                            cur.execute(f"""
                                INSERT INTO {table_name} (
                                    item_id, category, color, fit, material, print_pattern, style, length,
                                    category_confidence, color_confidence, fit_confidence
                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                            """, (
                                item_id, category_val, color_val, fit_val, material_val, print_val, style_val, length_val,
                                category_conf, color_conf, fit_conf
                            ))
                        elif category == 'ì•„ìš°í„°':
                            print(f"    ğŸ“ ì•„ìš°í„° INSERT ì‹¤í–‰: {table_name}")
                            print(f"    ğŸ“Š ê°’ë“¤: item_id={item_id}, category={category_val}, color={color_val}, material={material_val}")
                            try:
                                cur.execute(f"""
                                    INSERT INTO {table_name} (
                                        item_id, category, color, fit, material, print_pattern, style, sleeve_length,
                                        category_confidence, color_confidence, fit_confidence
                                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                                """, (
                                    item_id, category_val, color_val, fit_val, material_val, print_val, style_val, sleeve_val,
                                    category_conf, color_conf, fit_conf
                                ))
                                print(f"    âœ… ì•„ìš°í„° INSERT ì„±ê³µ!")
                            except Exception as e:
                                print(f"    âŒ ì•„ìš°í„° INSERT ì‹¤íŒ¨: {e}")
                                raise e
                        elif category == 'ì›í”¼ìŠ¤':
                            cur.execute(f"""
                                INSERT INTO {table_name} (
                                    item_id, category, color, material, print_pattern, style,
                                    category_confidence, color_confidence
                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                            """, (
                                item_id, category_val, color_val, material_val, print_val, style_val,
                                category_conf, color_conf
                            ))
                
                self.db_conn.commit()
                
            print(f"  - ì•„ì´í…œ ID: {item_id}")
            return item_id
            
        except Exception as e:
            try:
                self.db_conn.rollback()
                print(f"  âŒ PostgreSQL ì €ì¥ ì‹¤íŒ¨ (rollback ì™„ë£Œ): {e}")
            except:
                print(f"  âŒ PostgreSQL ì €ì¥ ì‹¤íŒ¨: {e}")
            raise e
    
    
    def save_to_chromadb(self, item_id: int, embedding: np.ndarray, 
                        metadata: Dict) -> str:
        """ChromaDBì— ì €ì¥"""
        print("[6/7] ChromaDBì— ì €ì¥ ì¤‘...")
        
        chroma_id = f"item_{item_id}"
        
        # ë©”íƒ€ë°ì´í„°ë¥¼ ë¬¸ì„œë¡œ ë³€í™˜
        doc_parts = []
        if metadata.get('style'):
            doc_parts.append(f"ìŠ¤íƒ€ì¼: {metadata['style']}")
        
        for category_en, category_ko in [('top', 'ìƒì˜'), ('bottom', 'í•˜ì˜'), ('outer', 'ì•„ìš°í„°'), ('dress', 'ì›í”¼ìŠ¤')]:
            if metadata.get(f'{category_en}_category'):
                doc_parts.append(f"{category_ko}: {metadata[f'{category_en}_category']}")
        
        document = " | ".join(doc_parts)
        
        self.chroma_collection.add(
            ids=[chroma_id],
            embeddings=[embedding.tolist()],
            metadatas=[metadata],
            documents=[document]
        )
        
        print(f"  - Chroma ID: {chroma_id}")
        return chroma_id
    
    
    def search_similar(self, embedding: np.ndarray, n_results: int = 5) -> list:
        """ìœ ì‚¬ ì•„ì´í…œ ê²€ìƒ‰"""
        print(f"[7/7] ìœ ì‚¬ ì•„ì´í…œ ê²€ìƒ‰ ì¤‘ (Top {n_results})...")
        
        results = self.chroma_collection.query(
            query_embeddings=[embedding.tolist()],
            n_results=n_results
        )
        
        print(f"  - ê²€ìƒ‰ ì™„ë£Œ: {len(results['ids'][0])}ê°œ")
        return results
    
    def remove_background_with_rembg(self, image: np.ndarray) -> np.ndarray:
        """
        Background Removerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ ì œê±°
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (RGB)
        
        Returns:
            transparent_image: íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ (RGBA)
        """
        if not self.rembg_available:
            print("âš ï¸ Background Removerê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None
        
        try:
            # PIL Imageë¡œ ë³€í™˜
            pil_image = Image.fromarray(image)
            
            # Background Removerë¡œ ë°°ê²½ ì œê±°
            transparent_image = remove(pil_image, session=self.rembg_session)
            
            # numpy arrayë¡œ ë³€í™˜
            transparent_array = np.array(transparent_image)
            
            return transparent_array
            
        except Exception as e:
            print(f"âŒ Background Remover ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    
    
    def process_image(self, image_path: str, user_id: int, 
                    save_separated_images: bool = False) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        print(f"\n{'='*60}")
        print(f"íŒŒì´í”„ë¼ì¸ ì‹œì‘: {image_path}")
        print(f"{'='*60}\n")
        
        try:
            # 1. ìŠ¤íƒ€ì¼ ì˜ˆì¸¡
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            style_result = self.predict_style(image_rgb)
            
            # 2. ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° í¬ë¡­
            detection_result = self.detect_and_crop_categories(image_path)
            
            # 3. ê° ì¹´í…Œê³ ë¦¬ë³„ ì†ì„± ì˜ˆì¸¡
            category_attributes = {}
            for category, item in detection_result['detected_items'].items():
                cropped_image = item['cropped_image']
                attributes = self.predict_category_attributes(category, cropped_image)
                category_attributes[category] = attributes
            
            # 4. ì„ë² ë”© ìƒì„±
            embedding = self.create_embedding(image_rgb)
            
            # 5. ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            metadata = {
                'user_id': str(user_id),
                'style': style_result['style'],
                'style_confidence': style_result['confidence']
            }
            
            for category, attributes in category_attributes.items():
                for attr_name, attr_data in attributes.items():
                    # ì¹´í…Œê³ ë¦¬ëª…ì„ ì˜ì–´ë¡œ ë³€í™˜
                    category_en = {'ìƒì˜': 'top', 'í•˜ì˜': 'bottom', 'ì•„ìš°í„°': 'outer', 'ì›í”¼ìŠ¤': 'dress'}[category]
                    metadata[f'{category_en}_{attr_name}'] = attr_data['value']
                    metadata[f'{category_en}_{attr_name}_confidence'] = attr_data['confidence']
            
            # 6. PostgreSQL ì €ì¥
            item_id = self.save_to_postgresql(
                user_id, image_path, style_result, detection_result,
                category_attributes, chroma_id=None
            )
            
            # 7. ChromaDB ì €ì¥
            chroma_id = self.save_to_chromadb(item_id, embedding, metadata)
            
            # 8. PostgreSQLì— chroma_id ì—…ë°ì´íŠ¸
            with self.db_conn.cursor() as cur:
                cur.execute("""
                    UPDATE wardrobe_items 
                    SET chroma_embedding_id = %s 
                    WHERE item_id = %s
                """, (chroma_id, item_id))
                self.db_conn.commit()
            
            # 9. ìœ ì‚¬ ì•„ì´í…œ ê²€ìƒ‰
            similar_items = self.search_similar(embedding, n_results=5)
            
            # 10. ë¶„ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
            if save_separated_images:
                base_dir = Path("./processed_images") / f"user_{user_id}"
                folders = {
                    'full': base_dir / 'full',
                    'top': base_dir / 'top',
                    'bottom': base_dir / 'bottom',
                    'outer': base_dir / 'outer',
                    'dress': base_dir / 'dress'
                }
                
                for folder in folders.values():
                    folder.mkdir(parents=True, exist_ok=True)
                
                # ì „ì²´ ì´ë¯¸ì§€ ì €ì¥
                full_path = folders['full'] / f"item_{item_id}_full.jpg"
                Image.fromarray(detection_result['original']).save(full_path)
                print(f"  âœ… ì „ì²´ ì´ë¯¸ì§€ ì €ì¥: {full_path}")
                
                # ê° ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ì €ì¥
                category_mapping = {
                    'ìƒì˜': 'top',
                    'í•˜ì˜': 'bottom', 
                    'ì•„ìš°í„°': 'outer',
                    'ì›í”¼ìŠ¤': 'dress'
                }
                
                for category_ko, category_en in category_mapping.items():
                    if category_ko in detection_result['detected_items']:
                        image_path_save = folders[category_en] / f"item_{item_id}_{category_en}.jpg"
                        Image.fromarray(detection_result['detected_items'][category_ko]['cropped_image']).save(image_path_save)
                        print(f"  âœ… {category_ko} ì €ì¥: {image_path_save}")
                
            
            print(f"\n{'='*60}")
            print(f"âœ” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print(f"  - ì•„ì´í…œ ID: {item_id}")
            print(f"  - Chroma ID: {chroma_id}")
            print(f"  - ìŠ¤íƒ€ì¼: {style_result['style']}")
            
            detected_categories = list(detection_result['detected_items'].keys())
            print(f"  - ê°ì§€ëœ ì˜ë¥˜: {', '.join(detected_categories)}")
            
            for category, attributes in category_attributes.items():
                if attributes:
                    print(f"  - {category}:")
                    for attr_name, attr_data in attributes.items():
                        print(f"    {attr_name}: {attr_data['value']}")
            
            print(f"{'='*60}\n")
            
            return {
                'success': True,
                'item_id': item_id,
                'chroma_id': chroma_id,
                'style_result': style_result,
                'detection_result': detection_result,
                'category_attributes': category_attributes,
                'similar_items': similar_items
            }
            
        except Exception as e:
            print(f"\nâœ— ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
            # âœ… íŠ¸ëœì­ì…˜ rollback (ì¶”ê°€)
            try:
                if hasattr(self, 'db_conn') and self.db_conn:
                    self.db_conn.rollback()
            except:
                pass
            
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_similar_items(self, image_path: str, n_results: int = 5) -> list:
        """ì£¼ì–´ì§„ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ì•„ì´í…œì„ ê²€ìƒ‰"""
        try:
            # 1. ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            embedding = self.create_embedding(image_rgb)
            
            # 2. ChromaDBì—ì„œ ìœ ì‚¬ ì•„ì´í…œ ê²€ìƒ‰
            search_results = self.search_similar(embedding, n_results)
            
            # 3. ê²°ê³¼ ì •ë¦¬
            item_ids = [int(id.replace("item_", "")) for id in search_results['ids'][0]]
            distances = search_results['distances'][0]
            
            results = []
            for i, item_id in enumerate(item_ids):
                results.append({
                    'item_id': item_id,
                    'distance': distances[i]
                })
                
            return results
        
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ ì•„ì´í…œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.db_conn:
            self.db_conn.close()
            print("PostgreSQL ì—°ê²° ì¢…ë£Œ")


# MultiTaskFashionModel ì •ì˜
class MultiTaskFashionModel(nn.Module):
    """Multi-task íŒ¨ì…˜ ì†ì„± ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, num_categories, num_colors, num_fits, num_materials):
        super().__init__()
        
        self.backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')
        num_features = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Identity()
        
        self.category_head = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_categories)
        )
        
        self.color_head = nn.Sequential(
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_colors)
        )
        
        self.fit_head = nn.Sequential(
            nn.Linear(num_features, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_fits)
        )
        
        self.material_head = nn.Sequential(
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_materials)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        
        category_out = self.category_head(features)
        color_out = self.color_head(features)
        fit_out = self.fit_head(features)
        material_out = self.material_head(features)
        
        return category_out, color_out, fit_out, material_out


class CategoryAttributeCNN(nn.Module):
    """ì¹´í…Œê³ ë¦¬ë³„ ì†ì„± ë¶„ë¥˜ CNN ëª¨ë¸"""
    
    def __init__(self, num_classes, pretrained=True):
        super(CategoryAttributeCNN, self).__init__()
        
        # ResNet50 ë°±ë³¸ ì‚¬ìš©
        self.backbone = models.resnet50(pretrained=pretrained)
        num_features = self.backbone.fc.in_features
        
        # ê¸°ì¡´ fc ë ˆì´ì–´ ì œê±°
        self.backbone.fc = nn.Identity()
        
        # ë¶„ë¥˜ í—¤ë“œ
        self.classifier = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        output = self.classifier(features)
        return output