"""
ì„±ë³„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
- K-Fashion ë°ì´í„°ì…‹ ì‚¬ìš©
- Male/Female ì´ì§„ ë¶„ë¥˜
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

# íŒŒì´í”„ë¼ì¸ ëª¨ë¸ import
from pipeline.models import GenderClassifier, GENDER_CLASSES


class GenderDataset(Dataset):
    """ì„±ë³„ ì˜ˆì¸¡ ë°ì´í„°ì…‹"""
    
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path} - {e}")
            # ë¹ˆ ì´ë¯¸ì§€ ë°˜í™˜
            image = Image.new('RGB', (224, 224), color='black')
        
        if self.transform:
            image = self.transform(image)
        
        label = self.labels[idx]
        return image, label


def load_kfashion_data(data_dir: str, csv_path: str = None):
    """
    K-Fashion ë°ì´í„°ì…‹ ë¡œë“œ
    
    Args:
        data_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        csv_path: ë¼ë²¨ CSV íŒŒì¼ ê²½ë¡œ (ìˆìœ¼ë©´)
    
    Returns:
        image_paths, labels (male=0, female=1)
    """
    print("\nğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    
    data_dir = Path(data_dir)
    
    if csv_path and Path(csv_path).exists():
        # CSV íŒŒì¼ì´ ìˆëŠ” ê²½ìš°
        print(f"  ğŸ“„ CSV íŒŒì¼ ì‚¬ìš©: {csv_path}")
        df = pd.read_csv(csv_path)
        
        # í•„ìš”í•œ ì»¬ëŸ¼: image_path, gender
        image_paths = []
        labels = []
        
        for idx, row in df.iterrows():
            img_path = data_dir / row['image_name']  # ë˜ëŠ” ì ì ˆí•œ ì»¬ëŸ¼ëª…
            if img_path.exists():
                image_paths.append(str(img_path))
                # gender ì»¬ëŸ¼ ê°’: 'male', 'female', 'ë‚¨ì„±', 'ì—¬ì„±' ë“±
                gender = row['gender'].lower()
                if 'male' in gender or 'ë‚¨' in gender:
                    labels.append(0)  # male
                elif 'female' in gender or 'ì—¬' in gender:
                    labels.append(1)  # female
        
    else:
        # í´ë” êµ¬ì¡°ë¡œ ë˜ì–´ ìˆëŠ” ê²½ìš°
        # data_dir/male/*.jpg
        # data_dir/female/*.jpg
        print(f"  ğŸ“ í´ë” êµ¬ì¡° ì‚¬ìš©: {data_dir}")
        
        image_paths = []
        labels = []
        
        # Male ì´ë¯¸ì§€
        male_dir = data_dir / 'male'
        if male_dir.exists():
            for img_path in male_dir.glob('*.jpg'):
                image_paths.append(str(img_path))
                labels.append(0)  # male
            for img_path in male_dir.glob('*.png'):
                image_paths.append(str(img_path))
                labels.append(0)
        
        # Female ì´ë¯¸ì§€
        female_dir = data_dir / 'female'
        if female_dir.exists():
            for img_path in female_dir.glob('*.jpg'):
                image_paths.append(str(img_path))
                labels.append(1)  # female
            for img_path in female_dir.glob('*.png'):
                image_paths.append(str(img_path))
                labels.append(1)
    
    print(f"  âœ… ì´ {len(image_paths)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ")
    print(f"  ğŸ“Š Male: {labels.count(0)}ê°œ, Female: {labels.count(1)}ê°œ")
    
    return image_paths, labels


def train_gender_model(
    data_dir: str,
    csv_path: str = None,
    batch_size: int = 32,
    epochs: int = 20,
    learning_rate: float = 0.001,
    save_path: str = "D:/kkokkaot/models/gender/best_model.pth"
):
    """
    ì„±ë³„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
    
    Args:
        data_dir: ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        csv_path: ë¼ë²¨ CSV íŒŒì¼ (ì„ íƒ)
        batch_size: ë°°ì¹˜ í¬ê¸°
        epochs: ì—í¬í¬ ìˆ˜
        learning_rate: í•™ìŠµë¥ 
        save_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
    """
    print("\n" + "="*60)
    print("ğŸ“ Gender ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print("="*60)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}")
    
    # ë°ì´í„° ë¡œë“œ
    image_paths, labels = load_kfashion_data(data_dir, csv_path)
    
    if len(image_paths) == 0:
        print("âŒ ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        print("\nğŸ’¡ ë°ì´í„° ì¤€ë¹„ ë°©ë²•:")
        print("  ë°©ë²• 1: í´ë” êµ¬ì¡°")
        print("    data_dir/")
        print("      â”œâ”€â”€ male/")
        print("      â”‚   â”œâ”€â”€ image1.jpg")
        print("      â”‚   â””â”€â”€ image2.jpg")
        print("      â””â”€â”€ female/")
        print("          â”œâ”€â”€ image3.jpg")
        print("          â””â”€â”€ image4.jpg")
        print("\n  ë°©ë²• 2: CSV íŒŒì¼")
        print("    CSV ì»¬ëŸ¼: image_name, gender")
        return
    
    # Train/Val ë¶„í• 
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        image_paths, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    print(f"\nğŸ“Š ë°ì´í„° ë¶„í• ")
    print(f"  Train: {len(train_paths)}ê°œ")
    print(f"  Val: {len(val_paths)}ê°œ")
    
    # ë°ì´í„° ì¦ê°•
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = GenderDataset(train_paths, train_labels, train_transform)
    val_dataset = GenderDataset(val_paths, val_labels, val_transform)
    
    # ë°ì´í„°ë¡œë”
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)
    
    # ëª¨ë¸ ìƒì„±
    print("\nğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
    model = GenderClassifier().to(device)
    
    # ì†ì‹¤ í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)
    
    # í•™ìŠµ ê¸°ë¡
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': []
    }
    
    best_val_acc = 0.0
    
    # í•™ìŠµ
    print(f"\nğŸš€ í•™ìŠµ ì‹œì‘ (Epochs: {epochs})")
    print("="*60)
    
    for epoch in range(epochs):
        # === Train ===
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]")
        for images, labels_batch in pbar:
            images = images.to(device)
            labels_batch = labels_batch.to(device)
            
            # Forward
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels_batch)
            
            # Backward
            loss.backward()
            optimizer.step()
            
            # í†µê³„
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels_batch.size(0)
            train_correct += predicted.eq(labels_batch).sum().item()
            
            # Progress bar ì—…ë°ì´íŠ¸
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{100.*train_correct/train_total:.2f}%'
            })
        
        train_loss /= len(train_loader)
        train_acc = 100. * train_correct / train_total
        
        # === Validation ===
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels_batch in tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]"):
                images = images.to(device)
                labels_batch = labels_batch.to(device)
                
                outputs = model(images)
                loss = criterion(outputs, labels_batch)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels_batch.size(0)
                val_correct += predicted.eq(labels_batch).sum().item()
        
        val_loss /= len(val_loader)
        val_acc = 100. * val_correct / val_total
        
        # ê¸°ë¡
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š Epoch {epoch+1}/{epochs}")
        print(f"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
        print(f"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        
        # Best ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            # ì €ì¥ ê²½ë¡œ í´ë” ìƒì„±
            Path(save_path).parent.mkdir(parents=True, exist_ok=True)
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'class_to_idx': {'male': 0, 'female': 1}
            }, save_path)
            print(f"  âœ… Best ëª¨ë¸ ì €ì¥! (Val Acc: {val_acc:.2f}%)")
        
        # Learning rate ì¡°ì •
        scheduler.step(val_loss)
        print("="*60)
    
    print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print(f"  Best Val Accuracy: {best_val_acc:.2f}%")
    print(f"  ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {save_path}")
    
    # í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    plot_training_history(history, save_path.replace('.pth', '_history.png'))
    
    return model, history


def plot_training_history(history, save_path):
    """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Loss
    ax1.plot(history['train_loss'], label='Train Loss')
    ax1.plot(history['val_loss'], label='Val Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Loss Curve')
    ax1.legend()
    ax1.grid(True)
    
    # Accuracy
    ax2.plot(history['train_acc'], label='Train Acc')
    ax2.plot(history['val_acc'], label='Val Acc')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.set_title('Accuracy Curve')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig(save_path)
    print(f"  ğŸ“Š í•™ìŠµ ê³¡ì„  ì €ì¥: {save_path}")


if __name__ == "__main__":
    # K-Fashion ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ
    train_gender_model(
        data_dir="D:/kkokkaot/API/man_woman",
        batch_size=32,
        epochs=30,
        learning_rate=0.001,
        save_path="D:/kkokkaot/models/gender/best_model.pth"
    )

