#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„° ë¶ˆì¼ì¹˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
CNN ë¼ë²¨ê³¼ í¬ë¡­ ì´ë¯¸ì§€ ìˆ˜ê°€ ë‹¤ë¥¸ ì´ìœ ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import os
import json
from pathlib import Path
from collections import defaultdict, Counter
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class DataMismatchAnalyzer:
    """ë°ì´í„° ë¶ˆì¼ì¹˜ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir="D:/converted_data"):
        self.data_dir = Path(data_dir)
        
        # ê²½ë¡œ ì„¤ì •
        self.cnn_labels_dir = self.data_dir / "prepared_data" / "cnn_labels"
        self.cropped_images_dir = self.data_dir / "prepared_data" / "cropped_images"
        self.original_cnn_dir = self.data_dir / "cnn"
        self.original_yolo_dir = self.data_dir / "yolo"
        self.images_dir = self.data_dir / "all_images"
        
        print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {self.data_dir}")
    
    def analyze_cnn_labels(self):
        """CNN ë¼ë²¨ ë¶„ì„"""
        print("\nğŸ” CNN ë¼ë²¨ ë¶„ì„ ì¤‘...")
        
        cnn_label_files = defaultdict(list)
        cnn_image_ids = defaultdict(set)
        
        categories = ['ìƒì˜', 'í•˜ì˜', 'ì•„ìš°í„°', 'ì›í”¼ìŠ¤']
        
        for category in categories:
            category_dir = self.cnn_labels_dir / category
            if category_dir.exists():
                files = list(category_dir.glob("*.json"))
                cnn_label_files[category] = files
                
                # ì´ë¯¸ì§€ ID ì¶”ì¶œ
                for file in files:
                    try:
                        with open(file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        image_id = data.get('image_id')
                        if image_id:
                            cnn_image_ids[category].add(image_id)
                    except Exception as e:
                        print(f"âš ï¸ CNN ë¼ë²¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {file}: {e}")
        
        print("CNN ë¼ë²¨ í†µê³„:")
        for category in categories:
            file_count = len(cnn_label_files[category])
            unique_images = len(cnn_image_ids[category])
            print(f"  {category}: {file_count}ê°œ íŒŒì¼, {unique_images}ê°œ ê³ ìœ  ì´ë¯¸ì§€")
        
        return cnn_label_files, cnn_image_ids
    
    def analyze_cropped_images(self):
        """í¬ë¡­ëœ ì´ë¯¸ì§€ ë¶„ì„"""
        print("\nğŸ” í¬ë¡­ëœ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        
        cropped_files = defaultdict(list)
        cropped_image_ids = defaultdict(set)
        
        categories = ['ìƒì˜', 'í•˜ì˜', 'ì•„ìš°í„°', 'ì›í”¼ìŠ¤']
        
        for category in categories:
            category_dir = self.cropped_images_dir / category
            if category_dir.exists():
                files = list(category_dir.glob("*.jpg"))
                cropped_files[category] = files
                
                # ì´ë¯¸ì§€ ID ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
                for file in files:
                    try:
                        # íŒŒì¼ëª… í˜•ì‹: imageID_category_sequence.jpg
                        filename = file.stem
                        parts = filename.split('_')
                        if len(parts) >= 2:
                            image_id = parts[0]
                            cropped_image_ids[category].add(image_id)
                    except Exception as e:
                        print(f"âš ï¸ í¬ë¡­ ì´ë¯¸ì§€ íŒŒì¼ëª… íŒŒì‹± ì˜¤ë¥˜ {file}: {e}")
        
        print("í¬ë¡­ëœ ì´ë¯¸ì§€ í†µê³„:")
        for category in categories:
            file_count = len(cropped_files[category])
            unique_images = len(cropped_image_ids[category])
            print(f"  {category}: {file_count}ê°œ íŒŒì¼, {unique_images}ê°œ ê³ ìœ  ì´ë¯¸ì§€")
        
        return cropped_files, cropped_image_ids
    
    def analyze_original_data(self):
        """ì›ë³¸ ë°ì´í„° ë¶„ì„"""
        print("\nğŸ” ì›ë³¸ ë°ì´í„° ë¶„ì„ ì¤‘...")
        
        # ì›ë³¸ CNN íŒŒì¼ë“¤
        original_cnn_files = list(self.original_cnn_dir.glob("*.json"))
        print(f"ì›ë³¸ CNN íŒŒì¼: {len(original_cnn_files)}ê°œ")
        
        # ì›ë³¸ YOLO íŒŒì¼ë“¤
        original_yolo_files = list(self.original_yolo_dir.glob("*.json"))
        print(f"ì›ë³¸ YOLO íŒŒì¼: {len(original_yolo_files)}ê°œ")
        
        # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ë“¤
        original_images = list(self.images_dir.glob("*.jpg"))
        print(f"ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼: {len(original_images)}ê°œ")
        
        return original_cnn_files, original_yolo_files, original_images
    
    def analyze_missing_images(self, cnn_image_ids, cropped_image_ids):
        """ëˆ„ë½ëœ ì´ë¯¸ì§€ ë¶„ì„"""
        print("\nğŸ” ëˆ„ë½ëœ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        
        categories = ['ìƒì˜', 'í•˜ì˜', 'ì•„ìš°í„°', 'ì›í”¼ìŠ¤']
        
        for category in categories:
            cnn_images = cnn_image_ids[category]
            cropped_images = cropped_image_ids[category]
            
            # CNNì—ëŠ” ìˆì§€ë§Œ í¬ë¡­ë˜ì§€ ì•Šì€ ì´ë¯¸ì§€ë“¤
            missing_in_cropped = cnn_images - cropped_images
            # í¬ë¡­ë˜ì—ˆì§€ë§Œ CNNì— ì—†ëŠ” ì´ë¯¸ì§€ë“¤ (ì¼ë°˜ì ìœ¼ë¡œ ì—†ì–´ì•¼ í•¨)
            extra_in_cropped = cropped_images - cnn_images
            
            print(f"\n{category} ë¶„ì„:")
            print(f"  CNN ë¼ë²¨ì—ë§Œ ìˆëŠ” ì´ë¯¸ì§€: {len(missing_in_cropped)}ê°œ")
            print(f"  í¬ë¡­ ì´ë¯¸ì§€ì—ë§Œ ìˆëŠ” ì´ë¯¸ì§€: {len(extra_in_cropped)}ê°œ")
            
            if missing_in_cropped:
                print(f"  ëˆ„ë½ëœ ì´ë¯¸ì§€ ID ì˜ˆì‹œ: {list(missing_in_cropped)[:10]}")
    
    def analyze_yolo_detection_failures(self, missing_image_ids):
        """YOLO ê°ì§€ ì‹¤íŒ¨ ë¶„ì„"""
        print("\nğŸ” YOLO ê°ì§€ ì‹¤íŒ¨ ë¶„ì„ ì¤‘...")
        
        detection_failures = []
        confidence_issues = []
        bbox_issues = []
        
        for image_id in tqdm(list(missing_image_ids)[:1000], desc="YOLO ë¶„ì„ ì¤‘"):  # ìƒ˜í”Œ ë¶„ì„
            yolo_file = self.original_yolo_dir / f"yolo_{image_id}.json"
            
            if not yolo_file.exists():
                detection_failures.append(image_id)
                continue
            
            try:
                with open(yolo_file, 'r', encoding='utf-8') as f:
                    yolo_data = json.load(f)
                
                if not yolo_data.get('annotations'):
                    detection_failures.append(image_id)
                    continue
                
                # ì‹ ë¢°ë„ ë¶„ì„
                low_confidence = True
                small_bbox = True
                
                for annotation in yolo_data['annotations']:
                    confidence = annotation.get('confidence', 0)
                    bbox = annotation.get('bbox', [0, 0, 0, 0])
                    
                    if confidence >= 0.5:
                        low_confidence = False
                    
                    if bbox[2] >= 32 and bbox[3] >= 32:  # width, height
                        small_bbox = False
                
                if low_confidence:
                    confidence_issues.append(image_id)
                if small_bbox:
                    bbox_issues.append(image_id)
                    
            except Exception as e:
                print(f"âš ï¸ YOLO íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {yolo_file}: {e}")
        
        print(f"YOLO ê°ì§€ ì‹¤íŒ¨ ì›ì¸ (ìƒ˜í”Œ 1000ê°œ ë¶„ì„):")
        print(f"  íŒŒì¼ ì—†ìŒ: {len(detection_failures)}ê°œ")
        print(f"  ì‹ ë¢°ë„ ë‚®ìŒ: {len(confidence_issues)}ê°œ")
        print(f"  ë°”ìš´ë”© ë°•ìŠ¤ ì‘ìŒ: {len(bbox_issues)}ê°œ")
    
    def check_image_file_availability(self, missing_image_ids):
        """ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê°€ìš©ì„± í™•ì¸"""
        print("\nğŸ” ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")
        
        missing_files = []
        available_files = []
        
        for image_id in tqdm(list(missing_image_ids)[:1000], desc="ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸ ì¤‘"):
            image_file = self.images_dir / f"{image_id}.jpg"
            
            if image_file.exists():
                available_files.append(image_id)
            else:
                missing_files.append(image_id)
        
        print(f"ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ìƒíƒœ (ìƒ˜í”Œ 1000ê°œ):")
        print(f"  íŒŒì¼ ìˆìŒ: {len(available_files)}ê°œ")
        print(f"  íŒŒì¼ ì—†ìŒ: {len(missing_files)}ê°œ")
        
        if missing_files:
            print(f"  ëˆ„ë½ëœ íŒŒì¼ ì˜ˆì‹œ: {missing_files[:10]}")
    
    def generate_report(self, cnn_image_ids, cropped_image_ids):
        """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        print("\nğŸ“Š ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        categories = ['ìƒì˜', 'í•˜ì˜', 'ì•„ìš°í„°', 'ì›í”¼ìŠ¤']
        
        report = {
            "summary": {
                "total_cnn_labels": sum(len(cnn_image_ids[cat]) for cat in categories),
                "total_cropped_images": sum(len(cropped_image_ids[cat]) for cat in categories),
                "total_missing": 0
            },
            "category_analysis": {},
            "recommendations": []
        }
        
        for category in categories:
            cnn_count = len(cnn_image_ids[category])
            cropped_count = len(cropped_image_ids[category])
            missing_count = cnn_count - cropped_count
            
            report["category_analysis"][category] = {
                "cnn_labels": cnn_count,
                "cropped_images": cropped_count,
                "missing": missing_count,
                "missing_rate": (missing_count / cnn_count * 100) if cnn_count > 0 else 0
            }
            
            report["summary"]["total_missing"] += missing_count
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if report["summary"]["total_missing"] > 0:
            report["recommendations"].append("YOLO ëª¨ë¸ì˜ ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš” (í˜„ì¬ 0.5)")
            report["recommendations"].append("ë°”ìš´ë”© ë°•ìŠ¤ ìµœì†Œ í¬ê¸° ì„ê³„ê°’ì„ ì¤„ì—¬ë³´ì„¸ìš” (í˜„ì¬ 32x32)")
            report["recommendations"].append("ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•˜ì„¸ìš”")
            report["recommendations"].append("CNN ë¼ë²¨ê³¼ YOLO ë¼ë²¨ì˜ ë°ì´í„° ì¼ê´€ì„±ì„ ê²€í† í•˜ì„¸ìš”")
        
        # ë³´ê³ ì„œ ì €ì¥
        report_file = self.data_dir / "prepared_data" / "data_mismatch_analysis.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        
        return report
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ” ë°ì´í„° ë¶ˆì¼ì¹˜ ë¶„ì„ ì‹œì‘!")
        print("=" * 60)
        
        try:
            # 1. CNN ë¼ë²¨ ë¶„ì„
            cnn_label_files, cnn_image_ids = self.analyze_cnn_labels()
            
            # 2. í¬ë¡­ëœ ì´ë¯¸ì§€ ë¶„ì„
            cropped_files, cropped_image_ids = self.analyze_cropped_images()
            
            # 3. ì›ë³¸ ë°ì´í„° ë¶„ì„
            self.analyze_original_data()
            
            # 4. ëˆ„ë½ëœ ì´ë¯¸ì§€ ë¶„ì„
            self.analyze_missing_images(cnn_image_ids, cropped_image_ids)
            
            # 5. YOLO ê°ì§€ ì‹¤íŒ¨ ë¶„ì„ (ìƒ˜í”Œ)
            all_cnn_images = set()
            for category_images in cnn_image_ids.values():
                all_cnn_images.update(category_images)
            
            all_cropped_images = set()
            for category_images in cropped_image_ids.values():
                all_cropped_images.update(category_images)
            
            missing_images = all_cnn_images - all_cropped_images
            
            if missing_images:
                self.analyze_yolo_detection_failures(missing_images)
                self.check_image_file_availability(missing_images)
            
            # 6. ë³´ê³ ì„œ ìƒì„±
            report = self.generate_report(cnn_image_ids, cropped_image_ids)
            
            print("\n" + "=" * 60)
            print("ğŸ“Š ë¶„ì„ ì™„ë£Œ!")
            print("=" * 60)
            
            print(f"ì´ CNN ë¼ë²¨: {report['summary']['total_cnn_labels']:,}ê°œ")
            print(f"ì´ í¬ë¡­ ì´ë¯¸ì§€: {report['summary']['total_cropped_images']:,}ê°œ")
            print(f"ì´ ëˆ„ë½: {report['summary']['total_missing']:,}ê°œ")
            
            print("\nì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸:")
            for category, data in report["category_analysis"].items():
                print(f"  {category}: {data['missing']:,}ê°œ ëˆ„ë½ ({data['missing_rate']:.1f}%)")
            
            if report["recommendations"]:
                print("\nê¶Œì¥ì‚¬í•­:")
                for i, rec in enumerate(report["recommendations"], 1):
                    print(f"  {i}. {rec}")
            
            return report
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ ë°ì´í„° ë¶ˆì¼ì¹˜ ë¶„ì„ ë„êµ¬")
    print("CNN ë¼ë²¨ê³¼ í¬ë¡­ ì´ë¯¸ì§€ ìˆ˜ê°€ ë‹¤ë¥¸ ì´ìœ ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    print("=" * 60)
    
    analyzer = DataMismatchAnalyzer()
    report = analyzer.run_analysis()
    
    if report:
        print("\nğŸ‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nğŸ’¥ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
