#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CNN ë¼ë²¨ í•™ìŠµ ì½”ë“œ
converted_data/cnn/ í´ë”ì˜ JSON ë¼ë²¨ê³¼ all_images/ í´ë”ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬
íŒ¨ì…˜ ì†ì„± ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import os
import json
import numpy as np
import pandas as pd
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class MultiTaskFashionDataset(Dataset):
    """ë©€í‹°íƒœìŠ¤í¬ íŒ¨ì…˜ ë°ì´í„°ì…‹ í´ë˜ìŠ¤"""
    
    def __init__(self, image_paths, multi_labels, transform=None):
        self.image_paths = image_paths
        self.multi_labels = multi_labels  # ê° ìƒ˜í”Œë³„ë¡œ ì—¬ëŸ¬ ì†ì„±ì˜ ë¼ë²¨ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        labels = self.multi_labels[idx]  # {'ìƒì˜_color': 0, 'ìƒì˜_fit': 1, ...}
        return image, labels

class MultiTaskFashionCNN(nn.Module):
    """ë©€í‹°íƒœìŠ¤í¬ íŒ¨ì…˜ ì†ì„± ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(self, attribute_configs, pretrained=True):
        super(MultiTaskFashionCNN, self).__init__()
        
        # ResNet50 ë°±ë³¸ ì‚¬ìš©
        self.backbone = models.resnet50(pretrained=pretrained)
        num_features = self.backbone.fc.in_features  # ResNet50: 2048
        
        # ê¸°ì¡´ fc ë ˆì´ì–´ ì œê±°
        self.backbone.fc = nn.Identity()
        
        # ê³µí†µ íŠ¹ì§• ì¶”ì¶œê¸°
        self.feature_extractor = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # ê° ì†ì„±ë³„ í—¤ë“œ
        self.attribute_heads = nn.ModuleDict()
        for attr_name, num_classes in attribute_configs.items():
            self.attribute_heads[attr_name] = nn.Sequential(
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, num_classes)
            )
    
    def forward(self, x):
        # ë°±ë³¸ íŠ¹ì§• ì¶”ì¶œ (ResNet50)
        features = self.backbone(x)  # shape: [batch_size, 2048]
        
        # ê³µí†µ íŠ¹ì§• ì¶”ì¶œ
        shared_features = self.feature_extractor(features)  # shape: [batch_size, 256]
        
        # ê° ì†ì„±ë³„ ì˜ˆì¸¡
        predictions = {}
        for attr_name, head in self.attribute_heads.items():
            predictions[attr_name] = head(shared_features)
        
        return predictions

class FashionLabelTrainer:
    """íŒ¨ì…˜ ë¼ë²¨ í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir="D:/converted_data", output_dir="D:/kkokkaot/API/pre_trained_weights/attributes"):
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ë°ì´í„° ê²½ë¡œ
        self.cnn_dir = self.data_dir / "cnn"
        self.images_dir = self.data_dir / "all_images"
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.image_paths = []
        self.labels = []
        self.label_encoders = {}
        
        # ëª¨ë¸ ì„¤ì •
        self.model = None
        self.criterion = None
        self.optimizer = None
        
        print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {self.data_dir}")
        print(f"ğŸ“ CNN ë¼ë²¨ ë””ë ‰í† ë¦¬: {self.cnn_dir}")
        print(f"ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {self.images_dir}")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
    
    def load_data(self, sample_ratio=1.0):
        """CNN JSON íŒŒì¼ê³¼ ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ”„ ë°ì´í„° ë¡œë”© ì‹œì‘...")
        
        # CNN JSON íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
        cnn_files = list(self.cnn_dir.glob("*.json"))
        print(f"ğŸ“Š ë°œê²¬ëœ CNN ë¼ë²¨ íŒŒì¼: {len(cnn_files)}ê°œ")
        
        # ìƒ˜í”Œë§ ì ìš©
        if sample_ratio < 1.0:
            import random
            random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´
            sample_size = int(len(cnn_files) * sample_ratio)
            cnn_files = random.sample(cnn_files, sample_size)
            print(f"ğŸ“Š ìƒ˜í”Œë§ ì ìš©: {sample_size}ê°œ íŒŒì¼ ì„ íƒ ({sample_ratio*100:.1f}%)")
        
        valid_data = []
        
        for cnn_file in tqdm(cnn_files, desc="ë°ì´í„° ì²˜ë¦¬ ì¤‘", leave=False):
            try:
                # JSON íŒŒì¼ ë¡œë“œ
                with open(cnn_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ í™•ì¸
                image_id = data['image_id']
                image_path = self.images_dir / f"{image_id}.jpg"
                
                if not image_path.exists():
                    continue
                
                # ë¼ë²¨ ì¶”ì¶œ
                labels = self.extract_labels(data)
                if labels:
                    valid_data.append({
                        'image_path': str(image_path),
                        'labels': labels
                    })
                    
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {cnn_file}: {e}")
                continue
        
        print(f"âœ… ìœ íš¨í•œ ë°ì´í„°: {len(valid_data)}ê°œ")
        
        # ë°ì´í„° ë¶„ë¦¬
        self.image_paths = [item['image_path'] for item in valid_data]
        self.labels = [item['labels'] for item in valid_data]
        
        return len(valid_data)
    
    def extract_labels(self, data):
        """JSON ë°ì´í„°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ"""
        labels = {}
        
        items = data.get('items', {})
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¼ë²¨ ì¶”ì¶œ
        for category in ['ìƒì˜', 'í•˜ì˜', 'ì•„ìš°í„°', 'ì›í”¼ìŠ¤']:
            if category in items and items[category]:
                item_data = items[category]
                
                # ì¹´í…Œê³ ë¦¬ ë¼ë²¨
                if 'ì¹´í…Œê³ ë¦¬' in item_data:
                    labels[f'{category}_category'] = item_data['ì¹´í…Œê³ ë¦¬']
                
                # ìƒ‰ìƒ ë¼ë²¨
                if 'ìƒ‰ìƒ' in item_data:
                    labels[f'{category}_color'] = item_data['ìƒ‰ìƒ']
                
                # í• ë¼ë²¨
                if 'í•' in item_data:
                    labels[f'{category}_fit'] = item_data['í•']
                
                # ì†Œì¬ ë¼ë²¨ (ë¦¬ìŠ¤íŠ¸)
                if 'ì†Œì¬' in item_data and item_data['ì†Œì¬']:
                    labels[f'{category}_material'] = item_data['ì†Œì¬'][0]  # ì²« ë²ˆì§¸ ì†Œì¬ë§Œ ì‚¬ìš©
                
                # ê¸°ì¥ ë¼ë²¨
                if 'ê¸°ì¥' in item_data and item_data['ê¸°ì¥']:
                    labels[f'{category}_length'] = item_data['ê¸°ì¥']
                
                # ì†Œë§¤ê¸°ì¥ ë¼ë²¨
                if 'ì†Œë§¤ê¸°ì¥' in item_data and item_data['ì†Œë§¤ê¸°ì¥']:
                    labels[f'{category}_sleeve_length'] = item_data['ì†Œë§¤ê¸°ì¥']
                
                # ë„¥ë¼ì¸ ë¼ë²¨
                if 'ë„¥ë¼ì¸' in item_data and item_data['ë„¥ë¼ì¸']:
                    labels[f'{category}_neckline'] = item_data['ë„¥ë¼ì¸']
                
                # í”„ë¦°íŠ¸ ë¼ë²¨ (ë¦¬ìŠ¤íŠ¸)
                if 'í”„ë¦°íŠ¸' in item_data and item_data['í”„ë¦°íŠ¸']:
                    labels[f'{category}_print'] = item_data['í”„ë¦°íŠ¸'][0]  # ì²« ë²ˆì§¸ í”„ë¦°íŠ¸ë§Œ ì‚¬ìš©
        
        
        return labels
    
    def prepare_training_data(self, target_attribute='ìƒì˜_category'):
        """íŠ¹ì • ì†ì„±ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        print(f"\nğŸ¯ íƒ€ê²Ÿ ì†ì„±: {target_attribute}")
        
        # í•´ë‹¹ ì†ì„±ì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        filtered_data = []
        for i, labels in enumerate(self.labels):
            if target_attribute in labels:
                filtered_data.append({
                    'image_path': self.image_paths[i],
                    'label': labels[target_attribute]
                })
        
        print(f"ğŸ“Š {target_attribute} ë°ì´í„°: {len(filtered_data)}ê°œ")
        
        if len(filtered_data) == 0:
            print("âŒ í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return None, None, None, None
        
        # ë¼ë²¨ ì¸ì½”ë”©
        label_encoder = LabelEncoder()
        all_labels = [item['label'] for item in filtered_data]
        encoded_labels = label_encoder.fit_transform(all_labels)
        
        self.label_encoders[target_attribute] = label_encoder
        
        # ë°ì´í„° ë¶„í• 
        image_paths = [item['image_path'] for item in filtered_data]
        X_train, X_test, y_train, y_test = train_test_split(
            image_paths, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels
        )
        
        print(f"ğŸ“ˆ í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
        print(f"ğŸ“ˆ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")
        print(f"ğŸ“ˆ í´ë˜ìŠ¤ ìˆ˜: {len(label_encoder.classes_)}ê°œ")
        print(f"ğŸ“ˆ í´ë˜ìŠ¤: {list(label_encoder.classes_)}")
        
        return X_train, X_test, y_train, y_test
    
    def create_data_loaders(self, X_train, X_test, y_train, y_test, batch_size=32):
        """ë°ì´í„° ë¡œë” ìƒì„±"""
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        train_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        test_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = MultiTaskFashionDataset(X_train, y_train, transform=train_transform)
        test_dataset = MultiTaskFashionDataset(X_test, y_test, transform=test_transform)
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
        
        return train_loader, test_loader
    
    def train_model(self, train_loader, test_loader, num_classes, target_attribute, epochs=30, learning_rate=0.001):
        """ëª¨ë¸ í•™ìŠµ"""
        print(f"\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (í´ë˜ìŠ¤ ìˆ˜: {num_classes})")
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ë‹¨ì¼ ì†ì„±ìš©)
        self.model = MultiTaskFashionCNN({target_attribute: num_classes}, pretrained=True).to(DEVICE)
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)
        
        # í•™ìŠµ ê¸°ë¡
        train_losses = []
        train_accuracies = []
        val_losses = []
        val_accuracies = []
        best_val_acc = 0.0
        
        # Early stopping ì„¤ì •
        patience = 5  # 5 ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
        patience_counter = 0
        
        for epoch in range(epochs):
            # í•™ìŠµ ë‹¨ê³„
            self.model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=False):
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                
                self.optimizer.zero_grad()
                outputs = self.model(images)
                loss = self.criterion(outputs[target_attribute], labels)
                loss.backward()
                self.optimizer.step()
                
                train_loss += loss.item()
                _, predicted = torch.max(outputs[target_attribute].data, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            # ê²€ì¦ ë‹¨ê³„
            self.model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0
            
            with torch.no_grad():
                for images, labels in test_loader:
                    images, labels = images.to(DEVICE), labels.to(DEVICE)
                    outputs = self.model(images)
                    loss = self.criterion(outputs[target_attribute], labels)
                    
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs[target_attribute].data, 1)
                    val_total += labels.size(0)
                    val_correct += (predicted == labels).sum().item()
            
            # í†µê³„ ê³„ì‚°
            train_loss /= len(train_loader)
            train_acc = 100 * train_correct / train_total
            val_loss /= len(test_loader)
            val_acc = 100 * val_correct / val_total

            train_losses.append(train_loss)
            train_accuracies.append(train_acc)
            val_losses.append(val_loss)
            val_accuracies.append(val_acc)

            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (ì†ì„±ë³„ë¡œ ë‹¤ë¥¸ íŒŒì¼ëª… ì‚¬ìš©)
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0  # ê°œì„ ë˜ë©´ ì¹´ìš´í„° ë¦¬ì…‹
                # í•œê¸€ì„ ì˜ì–´ë¡œ ë³€í™˜
                attr_name = target_attribute.replace('ìƒì˜', 'top').replace('í•˜ì˜', 'bottom').replace('ì•„ìš°í„°', 'outer').replace('ì›í”¼ìŠ¤', 'dress')
                model_filename = f'best_model_{attr_name}.pth'
                torch.save(self.model.state_dict(), self.output_dir / model_filename)
                print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_filename} (Val Acc: {val_acc:.2f}%)")
            else:
                patience_counter += 1  # ê°œì„ ì´ ì—†ìœ¼ë©´ ì¹´ìš´í„° ì¦ê°€
                print(f"â³ Early stopping counter: {patience_counter}/{patience}")
            
            scheduler.step()

            print(f"Epoch {epoch+1:3d}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, "
                f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

            # ì–¼ë¦¬ìŠ¤íƒ€í•‘ ì²´í¬
            if patience_counter >= patience:
                print(f"\nâš ï¸ Early stopping triggered! {patience} ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ì–´ í•™ìŠµì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.2f}%")
                break
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.2f}%")
        
        # í•™ìŠµ ê³¡ì„  ì €ì¥ë‹¤
        self.plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies)
        
        return best_val_acc
    
    def plot_training_curves(self, train_losses, train_accs, val_losses, val_accs):
        """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Loss ê³¡ì„ 
        ax1.plot(train_losses, label='Train Loss', color='blue')
        ax1.plot(val_losses, label='Validation Loss', color='red')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # Accuracy ê³¡ì„ 
        ax2.plot(train_accs, label='Train Accuracy', color='blue')
        ax2.plot(val_accs, label='Validation Accuracy', color='red')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'training_curves.png', dpi=300, bbox_inches='tight')
        # plt.show()
    
    def evaluate_model(self, test_loader, label_encoder):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
        
        self.model.eval()
        all_predictions = []
        all_labels = []
        
        with torch.no_grad():
            for images, labels in tqdm(test_loader, desc="í‰ê°€ ì¤‘", leave=False):
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = self.model(images)
                _, predicted = torch.max(outputs[list(outputs.keys())[0]], 1)
                
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        class_names = label_encoder.classes_
        report = classification_report(all_labels, all_predictions, target_names=class_names)
        print("\nğŸ“ˆ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
        print(report)
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(all_labels, all_predictions)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=class_names, yticklabels=class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')
        # plt.show()
        
        return report
    
    def save_model_info(self, target_attribute, num_classes, best_acc):
        """ëª¨ë¸ ì •ë³´ ì €ì¥"""
        # í•œê¸€ì„ ì˜ì–´ë¡œ ë³€í™˜
        attr_name = target_attribute.replace('ìƒì˜', 'top').replace('í•˜ì˜', 'bottom').replace('ì•„ìš°í„°', 'outer').replace('ì›í”¼ìŠ¤', 'dress')
        model_filename = f'best_model_{attr_name}.pth'
        info_filename = f'model_info_{attr_name}.json'
        
        model_info = {
            'target_attribute': target_attribute,
            'target_attribute_en': attr_name,
            'num_classes': num_classes,
            'class_names': self.label_encoders[target_attribute].classes_.tolist(),
            'best_accuracy': best_acc,
            'model_path': str(self.output_dir / model_filename)
        }
        
        with open(self.output_dir / info_filename, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ëª¨ë¸ ì •ë³´ ì €ì¥: {self.output_dir / info_filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ CNN ë¼ë²¨ í•™ìŠµ ì‹œì‘!")
    print("=" * 60)
    print(f"ğŸš€ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {DEVICE}")
    
    # í•™ìŠµê¸° ì´ˆê¸°í™”
    trainer = FashionLabelTrainer()
    
    # ë°ì´í„° ë¡œë“œ (20% ìƒ˜í”Œë§ìœ¼ë¡œ ë¹ ë¥¸ ì‹¤í—˜)
    sample_ratio = 0.2  # 20% ìƒ˜í”Œë§ (ë¹ ë¥¸ ì‹¤í—˜ìš©)
    num_data = trainer.load_data(sample_ratio=sample_ratio)
    if num_data == 0:
        print("âŒ ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ì„¤ì •
    category_models = {
        'ìƒì˜': {
            'attributes': ['color', 'fit', 'material', 'length', 'sleeve_length', 'neckline', 'print'],
            'display_name': 'ìƒì˜'
        },
        'í•˜ì˜': {
            'attributes': ['color', 'fit', 'material', 'length', 'print'],
            'display_name': 'í•˜ì˜'
        },
        'ì•„ìš°í„°': {
            'attributes': ['color', 'fit', 'material', 'length', 'sleeve_length', 'neckline', 'print'],
            'display_name': 'ì•„ìš°í„°'
        },
        'ì›í”¼ìŠ¤': {
            'attributes': ['color', 'fit', 'material', 'length', 'neckline', 'print'],
            'display_name': 'ì›í”¼ìŠ¤'
        }
    }
    
    
    results = {}
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ í•™ìŠµ
    for category, config in category_models.items():
        print(f"\n{'='*60}")
        print(f"ğŸ¯ {config['display_name']} ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print(f"ì†ì„±: {', '.join(config['attributes'])}")
        print(f"{'='*60}")
        
        try:
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê° ì†ì„±ë³„ë¡œ ê°œë³„ í•™ìŠµ (ì„ì‹œ)
            category_accuracies = []
            
            for attr in config['attributes']:
                target_attr = f'{category}_{attr}'
                print(f"  - {target_attr} í•™ìŠµ ì¤‘...")
                
                # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
                data = trainer.prepare_training_data(target_attr)
                if data is None:
                    continue
                    
                X_train, X_test, y_train, y_test = data
                
                # ë°ì´í„° ë¡œë” ìƒì„±
                train_loader, test_loader = trainer.create_data_loaders(
                    X_train, X_test, y_train, y_test, batch_size=64
                )
                
                # ëª¨ë¸ í•™ìŠµ
                num_classes = len(trainer.label_encoders[target_attr].classes_)
                best_acc = trainer.train_model(
                    train_loader, test_loader, num_classes, target_attr, epochs=2, learning_rate=0.001
                )
                
                category_accuracies.append(best_acc)
                print(f"    {target_attr}: {best_acc:.2f}%")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì •í™•ë„
            best_acc = sum(category_accuracies) / len(category_accuracies) if category_accuracies else 0
            
            results[f'{category}_multitask'] = best_acc
            
            print(f"âœ… {config['display_name']} ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! í‰ê·  ì •í™•ë„: {best_acc:.2f}%")
            
        except Exception as e:
            print(f"âŒ {config['display_name']} ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            continue
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print("ğŸ“Š ì „ì²´ í•™ìŠµ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*60}")
    
    for attr, acc in results.items():
        print(f"{attr:20s}: {acc:6.2f}%")
    
    print(f"\nğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {trainer.output_dir}")
    
    # ê²°ê³¼ ìš”ì•½ txt íŒŒì¼ ì €ì¥
    summary_file = trainer.output_dir / 'training_summary.txt'
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ¯ CNN ë¼ë²¨ í•™ìŠµ ê²°ê³¼ ìš”ì•½\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"ğŸ“… í•™ìŠµ ì™„ë£Œ ì‹œê°„: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {trainer.output_dir}\n")
        f.write(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}\n")
        f.write(f"ğŸ“Š ë°ì´í„° ìƒ˜í”Œë§: {sample_ratio*100:.1f}% (ë¹ ë¥¸ ì‹¤í—˜ìš©)\n\n")
        
        f.write("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë¸ ì„±ëŠ¥:\n")
        f.write("-" * 40 + "\n")
        
        for attr, acc in results.items():
            f.write(f"{attr:25s}: {acc:6.2f}%\n")
        
        f.write("\nğŸ¯ í•™ìŠµëœ ëª¨ë¸ ëª©ë¡:\n")
        f.write("-" * 40 + "\n")
        
        for category, config in category_models.items():
            f.write(f"\n{config['display_name']} ëª¨ë¸:\n")
            for attr in config['attributes']:
                f.write(f"  - {category}_{attr}\n")
        
        f.write(f"\nğŸ“ˆ ì´ í•™ìŠµëœ ì†ì„± ìˆ˜: {sum(len(config['attributes']) for config in category_models.values())}ê°œ\n")
        f.write(f"ğŸ“ˆ ì´ ëª¨ë¸ ìˆ˜: {len(category_models)}ê°œ\n")
        
        f.write("\n" + "=" * 60 + "\n")
        f.write("ğŸ‰ ëª¨ë“  í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n")
    
    print(f"ğŸ“„ ê²°ê³¼ ìš”ì•½ íŒŒì¼ ì €ì¥: {summary_file}")

if __name__ == "__main__":
    main()